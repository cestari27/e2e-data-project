resources:
  jobs:
    data_ingestion_job:
      name: "Iris Data Ingestion Job - ${var.environment}"
      description: "Job to ingest iris dataset from sklearn into Unity Catalog"
      
      # Email notifications on failure
      email_notifications:
        on_failure:
          - "pedro.zanlorensi@databricks.com"
        no_alert_for_skipped_runs: false
      
      # Job parameters
      parameters:
        - name: "catalog_name"
          default: "${var.catalog_name}"
      
      # Job tasks
      tasks:
        - task_key: "ingest_data"
          description: "Ingest iris dataset into Unity Catalog"
          
          # Use default serverless compute
          compute:
            spec:
              kind: "serverless"
          
          # Notebook task
          notebook_task:
            notebook_path: "../Notebooks/1_DataPreprocessing/data-ingestion.ipynb"
            base_parameters:
              catalog_name: "{{job.parameters.catalog_name}}"
      
      # Timeout and retry settings
      timeout_seconds: 3600
      max_concurrent_runs: 1
      
      # Tags for organization
      tags:
        Environment: "${var.environment}"
        Project: "e2e-data-project" 